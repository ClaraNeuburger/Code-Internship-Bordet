{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "610adee2",
   "metadata": {},
   "source": [
    "The following code serves as a representation of the workflow followed during this research internship. \n",
    "\n",
    "The goal is to exploit a dataset of full body PET MRI (T2 and dixon sequences) and CT to build and train a model which can create synthetic CT from the MRI images. The goal then using these sCT is to use them for body composition:  https://github.com/UMEssen/Body-and-Organ-Analysis\n",
    "\n",
    "Body composition is a biomarker which can be used to determine treatment plans in oncology, cardiology. The CT image is fed to a software which will separate it into different regions thanks to a model that thresholds the HU to a specific intensity range. The regions to be determine are : \n",
    "- Subcutaneous adipose tissue\n",
    "- Total adipose tissue\n",
    "- Visceral adipose tissue\n",
    "- Muscle volume\n",
    "\n",
    "The software used also allows an organ segmentation of the trunk whiwh can also be later tested with the sCT. \n",
    "\n",
    "The advantage of creating such a sCT is to be able to be able to produce this body composition report without the need for an irradiating scan. Past models for creating sCT at the Bordet Institute were intended for radiotherapy treatments. The main difference here is that there is no need for such precision for body composition because we are more interested in global composition then the exact position of every organ in the scan. \n",
    "\n",
    "From the time being, the data is not yet recovered, the following code was used to explore torchio functionalities and learn how to load medical data into a model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4638f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import torch \n",
    "import torchio as tio\n",
    "from torch.utils.data import DataLoader\n",
    "import pydicom\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf28c91",
   "metadata": {},
   "source": [
    "### Load the data using torchio "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422dcc77",
   "metadata": {},
   "source": [
    "It is often recommended to use NIfTI format for managing medical images, why? what are the advantages compared with simply working with dicom format?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bea10d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_dataset(rootdir):\n",
    "    file_paths = []\n",
    "    subject_paths = []\n",
    "    subjects_list = []\n",
    "    nb_subjects = 0\n",
    "    \n",
    "    # Start by recovering the path to the subjects\n",
    "    for subjects in os.listdir(rootdir):\n",
    "        subject_path = os.path.join(rootdir,subjects)\n",
    "        subject_paths.append(subject_path)\n",
    "        nb_subjects += 1\n",
    "   \n",
    "    for subject_path in subject_paths:\n",
    "        # Recover all the files\n",
    "        for files in os.listdir(subject_path):\n",
    "            file_path= os.path.join(subject_path,files)\n",
    "            file_paths.append(file_path)\n",
    "        \n",
    "        # Create the subject format of torchio witht the scans and the id of the patient\n",
    "        sub = tio.Subject(\n",
    "            CT = tio.ScalarImage(subject_path),\n",
    "            id_patient = os.path.basename(subject_path),\n",
    "        ) \n",
    "        \n",
    "        subjects_list.append(sub)\n",
    "        \n",
    "        # List of transforms\n",
    "        transforms = [\n",
    "            tio.ToCanonical(),\n",
    "            tio.Clamp(out_min=0,out_max = 2500),\n",
    "            tio.RescaleIntensity(out_min_max=(-1,1)),\n",
    "        ]\n",
    "        \n",
    "        # Create our own set of tranforms that we will apply to our dataset\n",
    "        transform = tio.Compose(transforms)\n",
    "    \n",
    "    # Create the final data set made of the different subjects\n",
    "   \n",
    "    dataset = tio.SubjectsDataset(subjects_list, transform=transform)\n",
    "    print('Dataset successfully created! The set is made of',nb_subjects,'patients.')\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f627c277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset successfully created! The set is made of 8 patients.\n"
     ]
    }
   ],
   "source": [
    "dataset = Create_dataset('../sCT code/data prostate')\n",
    "\n",
    "# The plot of a Subject object will build the coronal and axial view when we only send it the sagittal view\n",
    "# dataset[0].plot()\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f251dc26",
   "metadata": {},
   "source": [
    "Now that the dataset is crated with 3D images for each subject, we need to decide how to exploit them: do we keep them 3D in the model or do we explore them slice by slice to achieve a 2D analysis?\n",
    "\n",
    "The following part will explore how this dataset can be included and preprocessed before feeding it to the model. \n",
    "It is important to specify that with the real data, some pre processing steps might be done using mice software to re-align the PET MRI with the CT (make sure they have the same zero and that morphological differences are not too disturbing).\n",
    "\n",
    "A crucial notion to this project is to make sure that the model and preprocessing steps chosen will match the concrete clinical applications. \n",
    "\n",
    "The issue with medical images is their quantity, they often contain hundreds of milions of voxels and cannot always be downsampled. \n",
    "Big differences are to be noted when working with medical images: their size, the fact that they might be 3D, their format (often DICOM which contains metadata about the patient), the fact that they cannot be easily downsampled if details are needed. \n",
    "\n",
    "The batch size of medical images tend to be way smaller than the usual ones because of the quantity of information contained in a single medical image. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b51b103",
   "metadata": {},
   "source": [
    "### Create patches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd51e9a",
   "metadata": {},
   "source": [
    "To train in 2D, one need to extract slices from 3D volumes, aggrefating the inference results to generate a 3D volume: this is called batch based training, the patches along a dimension is one (cite Torchio patch based pipeline). \n",
    "\n",
    "In torchio it is possible to use patch samplers: functions that will randomly extract pathces from volumes when fed a SubjectDataset like we created earlier. \n",
    "We tend to use batch sampling when working with medical images because of their size: working with smaller patches reduce computation. It has also been proven that soemtimes, algorithms using patches can be more efficient, it is the case for denoising for example. \n",
    "\n",
    "You could chose Uniform or Weighted patching: uniform will take random patches from a volume with a uniform probabiliy while the weighted sampler will randomly extract patches given a probability map. \n",
    "If you chose very small patches, it could be intersting to create a probability map for each slice in order to focus on the region of interest and not consider much the background. \n",
    "However with larger patches, a uniform sampler is easier to use. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f559f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNIFORM sampler\n",
    "# Chose the sampler for your data\n",
    "sampler_uniform = tio.data.UniformSampler(patch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d72c4883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WEIGHTED sampler \n",
    "\n",
    "dicom_dir = 'path_to_your_dicom_directory'\n",
    "\n",
    "dicom_files = [pydicom.dcmread(os.path.join(dicom_dir, f)) for f in sorted(os.listdir(dicom_dir)) if f.endswith('.dcm')]\n",
    "\n",
    "slices = [dicom_file.pixel_array for dicom_file in dicom_files]\n",
    "\n",
    "\n",
    "image_np = np.stack(slices, axis=0)\n",
    "\n",
    "image_tensor = torch.tensor(image_np, dtype=torch.float32)\n",
    "\n",
    "\n",
    "\n",
    "threshold = 1000  \n",
    "\n",
    "probability_map = torch.zeros_like(image_tensor)\n",
    "\n",
    "\n",
    "for i in range(image_tensor.shape[0]):\n",
    "    slice_2d = image_tensor[i, :, :]\n",
    "    probability_map[i, :, :] = (slice_2d > threshold).float()\n",
    "\n",
    "\n",
    "sampler = tio.data.WeightedSampler(probability_map, patch_size=(32, 32, 32))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
